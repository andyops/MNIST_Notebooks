{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This Notebook implements the TensorFlow advanced tutorial which uses a Multilayer Convolutional Network on the MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../datasets/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at sizes of training, validation and test sets Each image is 28 X 28 pixels Labels are in one hot encoding for use with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1191f3c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.num_examples)\n",
    "print(mnist.validation.num_examples)\n",
    "print(mnist.test.num_examples)\n",
    "plt.imshow(mnist.train.images[10004].reshape(28,28),cmap=\"Greys\")\n",
    "plt.show()\n",
    "print (mnist.train.labels[10004])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Initialization for ReLU nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution and Pooling operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Convolutional Layer**\n",
    "The convolution will compute 32 features for each 5x5 patch. The max_pool_2x2 method will reduce the image size to 14x14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Convolutional Layer** The second layer will have 64 features for each 5x5 patch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Densely Connected Layer** The image size has been reduced to 7x7 and we add a fully-connected layer with 1024 neurons to allow processing on the entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Readout Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that runs the model for given number of batches and returns the training time and accuracy on the validations and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(batches,batches_per_epoch,verbose=False):\n",
    "    start = time.time()\n",
    "    epoch = 1\n",
    "    results = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(batches):\n",
    "            batch = mnist.train.next_batch(50)  \n",
    "            if i % 100 == 0 and verbose:\n",
    "                train_accuracy = accuracy.eval(feed_dict={\n",
    "                    x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "                print('step %d, training accuracy %g, elapsedtime %g' % (i, train_accuracy, time.time() - start))\n",
    "            train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "            if (i+1) % batches_per_epoch == 0:\n",
    "                test_accuracy = accuracy.eval(feed_dict={\n",
    "                    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "                validation_accuracy = accuracy.eval(feed_dict={\n",
    "                    x: mnist.validation.images, y_: mnist.validation.labels, keep_prob: 1.0})\n",
    "                if verbose:\n",
    "                    print('Done with test/val accuracy elapsed time %g' % (time.time() - start))\n",
    "                train_accuracy = accuracy.eval(feed_dict={\n",
    "                    x: mnist.train.images[0:10000], y_: mnist.train.labels[0:10000], keep_prob: 1.0})\n",
    "                if verbose:\n",
    "                    print('Done with train accuracy elapsed time %g' % (time.time() - start))\n",
    "                time_elapsed = time.time() - start\n",
    "                if verbose:\n",
    "                    print(epoch,i+1, time_elapsed, train_accuracy, validation_accuracy, test_accuracy)\n",
    "                results.append((epoch,time_elapsed, train_accuracy, validation_accuracy, test_accuracy))\n",
    "                epoch += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1, elapsedtime 0.280307\n",
      "step 100, training accuracy 0.82, elapsedtime 22.0599\n",
      "step 200, training accuracy 0.94, elapsedtime 39.533\n",
      "step 300, training accuracy 0.94, elapsedtime 56.9026\n",
      "step 400, training accuracy 0.94, elapsedtime 74.9775\n",
      "step 500, training accuracy 0.98, elapsedtime 92.3506\n",
      "step 600, training accuracy 0.98, elapsedtime 109.784\n",
      "step 700, training accuracy 0.88, elapsedtime 127.871\n",
      "step 800, training accuracy 0.98, elapsedtime 145.687\n",
      "step 900, training accuracy 0.96, elapsedtime 163.3\n",
      "step 1000, training accuracy 1, elapsedtime 180.715\n",
      "Done with test/val accuracy elapsed time 221.807\n",
      "Done with train accuracy elapsed time 236.237\n",
      "1 1100 236.23753309249878 0.9658 0.969 0.9679\n",
      "step 1100, training accuracy 1, elapsedtime 236.315\n",
      "step 1200, training accuracy 0.98, elapsedtime 254.228\n",
      "step 1300, training accuracy 1, elapsedtime 271.384\n",
      "step 1400, training accuracy 1, elapsedtime 289.574\n",
      "step 1500, training accuracy 1, elapsedtime 314.555\n",
      "step 1600, training accuracy 1, elapsedtime 342.109\n",
      "step 1700, training accuracy 1, elapsedtime 363.13\n",
      "step 1800, training accuracy 0.96, elapsedtime 382.762\n",
      "step 1900, training accuracy 1, elapsedtime 403.432\n",
      "step 2000, training accuracy 1, elapsedtime 428.944\n",
      "step 2100, training accuracy 1, elapsedtime 450.401\n",
      "Done with test/val accuracy elapsed time 504.18\n",
      "Done with train accuracy elapsed time 524.637\n",
      "2 2200 524.637166261673 0.98 0.979 0.9756\n",
      "step 2200, training accuracy 0.96, elapsedtime 524.744\n",
      "step 2300, training accuracy 0.98, elapsedtime 544.233\n",
      "step 2400, training accuracy 1, elapsedtime 564.936\n",
      "step 2500, training accuracy 1, elapsedtime 585.462\n",
      "step 2600, training accuracy 1, elapsedtime 611.384\n",
      "step 2700, training accuracy 1, elapsedtime 630.225\n",
      "step 2800, training accuracy 0.98, elapsedtime 648.963\n",
      "step 2900, training accuracy 0.94, elapsedtime 667.34\n",
      "step 3000, training accuracy 0.98, elapsedtime 686.215\n",
      "step 3100, training accuracy 0.98, elapsedtime 704.684\n",
      "step 3200, training accuracy 0.96, elapsedtime 722.58\n",
      "Done with test/val accuracy elapsed time 765.576\n",
      "Done with train accuracy elapsed time 782.505\n",
      "3 3300 782.5050911903381 0.9869 0.9836 0.982\n",
      "step 3300, training accuracy 1, elapsedtime 782.575\n",
      "step 3400, training accuracy 1, elapsedtime 807.521\n",
      "step 3500, training accuracy 0.98, elapsedtime 830.926\n",
      "step 3600, training accuracy 1, elapsedtime 865.648\n",
      "step 3700, training accuracy 1, elapsedtime 894.313\n",
      "step 3800, training accuracy 0.94, elapsedtime 918.628\n",
      "step 3900, training accuracy 0.96, elapsedtime 943.675\n",
      "step 4000, training accuracy 0.94, elapsedtime 963.091\n",
      "step 4100, training accuracy 1, elapsedtime 980.994\n",
      "step 4200, training accuracy 1, elapsedtime 1000.05\n",
      "step 4300, training accuracy 0.98, elapsedtime 1017.86\n",
      "Done with test/val accuracy elapsed time 1058.87\n",
      "Done with train accuracy elapsed time 1073.94\n",
      "4 4400 1073.937301158905 0.9907 0.986 0.9849\n",
      "step 4400, training accuracy 0.98, elapsedtime 1074.02\n",
      "step 4500, training accuracy 0.98, elapsedtime 1091.76\n",
      "step 4600, training accuracy 1, elapsedtime 1109.88\n",
      "step 4700, training accuracy 1, elapsedtime 1132.62\n",
      "step 4800, training accuracy 1, elapsedtime 1154.38\n",
      "step 4900, training accuracy 1, elapsedtime 1173.18\n",
      "step 5000, training accuracy 1, elapsedtime 1190.52\n",
      "step 5100, training accuracy 1, elapsedtime 1207.73\n",
      "step 5200, training accuracy 1, elapsedtime 1227.23\n",
      "step 5300, training accuracy 1, elapsedtime 1246.24\n",
      "step 5400, training accuracy 0.98, elapsedtime 1264.91\n",
      "Done with test/val accuracy elapsed time 1304\n",
      "Done with train accuracy elapsed time 1317.59\n",
      "5 5500 1317.5895881652832 0.9933 0.9888 0.9878\n",
      "step 5500, training accuracy 1, elapsedtime 1317.65\n",
      "step 5600, training accuracy 1, elapsedtime 1334.75\n",
      "step 5700, training accuracy 1, elapsedtime 1353\n",
      "step 5800, training accuracy 0.98, elapsedtime 1372.71\n",
      "step 5900, training accuracy 1, elapsedtime 1390.5\n",
      "step 6000, training accuracy 1, elapsedtime 1409.37\n",
      "step 6100, training accuracy 1, elapsedtime 1427.49\n",
      "step 6200, training accuracy 0.98, elapsedtime 1450.1\n",
      "step 6300, training accuracy 1, elapsedtime 1467.87\n",
      "step 6400, training accuracy 1, elapsedtime 1484.91\n",
      "step 6500, training accuracy 0.98, elapsedtime 1502.14\n",
      "Done with test/val accuracy elapsed time 1540.41\n",
      "Done with train accuracy elapsed time 1553.68\n",
      "6 6600 1553.676022052765 0.9956 0.9904 0.988\n",
      "step 6600, training accuracy 1, elapsedtime 1553.74\n",
      "step 6700, training accuracy 1, elapsedtime 1570.58\n",
      "step 6800, training accuracy 0.98, elapsedtime 1589.09\n",
      "step 6900, training accuracy 0.98, elapsedtime 1607\n",
      "step 7000, training accuracy 0.98, elapsedtime 1623.99\n",
      "step 7100, training accuracy 1, elapsedtime 1641.07\n",
      "step 7200, training accuracy 1, elapsedtime 1658.14\n",
      "step 7300, training accuracy 1, elapsedtime 1675.7\n",
      "step 7400, training accuracy 1, elapsedtime 1692.83\n",
      "step 7500, training accuracy 1, elapsedtime 1710.9\n",
      "step 7600, training accuracy 1, elapsedtime 1727.64\n",
      "Done with test/val accuracy elapsed time 1766.37\n",
      "Done with train accuracy elapsed time 1781.1\n",
      "7 7700 1781.1031889915466 0.9965 0.9912 0.9896\n",
      "(1, 236.23753309249878, 0.96579999, 0.96899998, 0.96789998)\n",
      "(2, 524.637166261673, 0.98000002, 0.97899997, 0.9756)\n",
      "(3, 782.5050911903381, 0.98689997, 0.98360002, 0.98199999)\n",
      "(4, 1073.937301158905, 0.99070001, 0.986, 0.9849)\n",
      "(5, 1317.5895881652832, 0.99330002, 0.98879999, 0.9878)\n",
      "(6, 1553.676022052765, 0.99559999, 0.99040002, 0.98799998)\n",
      "(7, 1781.1031889915466, 0.99650002, 0.99119997, 0.9896)\n"
     ]
    }
   ],
   "source": [
    "results=train_and_test_model(7700,1100,verbose=True)\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num Epochs | Train Time | Training Accuracy | Validation Accuracy | Test Accuracy\n",
    "---------- | ---------- | ----------------- |-------------------- | -------------\n",
    "1 |  236.2375 | 0.9658 | 0.9690 | 0.9679\n",
    "2 |  524.6372 | 0.9800 | 0.9790 | 0.9756\n",
    "3 |  782.5051 | 0.9869 | 0.9836 | 0.9820\n",
    "4 | 1073.9373 | 0.9907 | 0.9860 | 0.9849\n",
    "5 | 1317.5896 | 0.9933 | 0.9888 | 0.9878\n",
    "6 | 1553.6760 | 0.9956 | 0.9904 | 0.9880\n",
    "7 | 1781.1032 | 0.9965 | 0.9912 | 0.9896\n",
    "\n",
    "The tutorial achieved 99.2% accuracy after 20000 batches, >18 epoch, in about 30 minutes. This notebook on my laptop, ran 7 epochs in about 30 minutes and achieved around 99% accuracy. We will use this as the benchmark to aim for the numpy based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
