{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This Notebook implements the TensorFlow tutorial which uses SoftMax Logistic Regression on the MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../datasets/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at sizes of training, validation and test sets\n",
    "Each image is 28 X 28 pixels\n",
    "Labels are in one hot encoding for use with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117435940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.num_examples)\n",
    "print(mnist.validation.num_examples)\n",
    "print(mnist.test.num_examples)\n",
    "plt.imshow(mnist.train.images[30].reshape(28,28),cmap=\"Greys\")\n",
    "plt.show()\n",
    "print (mnist.train.labels[30])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that runs the model for given number of batches and returns the training time and accuracy on the training, validation and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_model(batches, verbose=False):\n",
    "    start = time.time()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for _ in range(batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        train_time = time.time() - start\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x: mnist.train.images, y_: mnist.train.labels})\n",
    "        validation_accuracy = sess.run(accuracy, feed_dict={x: mnist.validation.images, y_: mnist.validation.labels})\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        if verbose:\n",
    "            print(batches, train_time, train_accuracy, validation_accuracy, test_accuracy)\n",
    "        return (train_time, train_accuracy, validation_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial runs a 1000 batches each of size 100 which is about 2 epochs with 55000 test images. Lets run the model for 1, 2 and 5 epochs and see how accuracy changes with longer training time and also record how long it takes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 0.670133113861084 0.912527 0.9182 0.9185\n",
      "1100 1.654205083847046 0.918 0.9234 0.9185\n",
      "2750 3.115687131881714 0.924782 0.9232 0.9246\n",
      "5500 6.5319788455963135 0.928273 0.9262 0.9219\n",
      "11000 12.81721806526184 0.927345 0.9236 0.9228\n",
      "13750 15.79944109916687 0.932582 0.9256 0.9268\n",
      "(0.670133113861084, 0.91252726, 0.91820002, 0.91850001) (1.654205083847046, 0.91799998, 0.92339998, 0.91850001) (3.115687131881714, 0.9247818, 0.92320001, 0.92460001) (6.5319788455963135, 0.92827272, 0.92619997, 0.92189997) (12.81721806526184, 0.92734545, 0.92360002, 0.9228) (15.79944109916687, 0.93258184, 0.92559999, 0.92680001)\n"
     ]
    }
   ],
   "source": [
    "one_epoch = train_and_test_model(550,verbose=True)\n",
    "two_epoch = train_and_test_model(1100,verbose=True)\n",
    "five_epoch = train_and_test_model(2750,verbose=True)\n",
    "ten_epoch = train_and_test_model(5500,verbose=True)\n",
    "twenty_epoch = train_and_test_model(11000,verbose=True)\n",
    "twentyfive_epoch = train_and_test_model(13750,verbose=True)\n",
    "print(one_epoch,two_epoch,five_epoch,ten_epoch,twenty_epoch,twentyfive_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num Epochs | Train Time | Training Accuracy | Validation Accuracy | Test Accuracy\n",
    "---------- | ---------- | ----------------- |-------------------- | -------------\n",
    "1          | 0.6701     | 0.9125            | 0.9182              | 0.9185\n",
    "2          | 1.6542     | 0.9180            | 0.9234              | 0.9185\n",
    "5          | 3.1157     | 0.9248            | 0.9232              | 0.9246\n",
    "10         | 6.5320     | 0.9282            | 0.9262              | 0.9219\n",
    "20         | 12.8172    | 0.9273            | 0.9236              | 0.9228\n",
    "25         | 15.7994    | 0.9326            | 0.9256              | 0.9268"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like training the model for more than 5 epochs does not improve training accuracy significantly and validation/test accuracy has plateaued. So running 5 epochs in 3.2 seconds for training and 92.5% accuracy looks like the benchmark to aim for while developing a hand coded model using numpy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
